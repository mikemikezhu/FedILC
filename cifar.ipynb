{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "92a96954d814418289a94f212fa9df68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23768ce6627747668eee1d9fe5036790",
              "IPY_MODEL_c63b25e173bc45ba97cf8c750b76ab19",
              "IPY_MODEL_918aa19f47fa4620859ec03c7bc4be76"
            ],
            "layout": "IPY_MODEL_2e39ad257bcc41bd8330c125f0116fd3"
          }
        },
        "23768ce6627747668eee1d9fe5036790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a5f6cb5b63c41d49848c6106568d99b",
            "placeholder": "​",
            "style": "IPY_MODEL_38a45412449949b790408f332821c8a2",
            "value": ""
          }
        },
        "c63b25e173bc45ba97cf8c750b76ab19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_322226b73b3542f882889fa2d1b82731",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_abd731f91d1c4566b3f144f91e04954c",
            "value": 170498071
          }
        },
        "918aa19f47fa4620859ec03c7bc4be76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ab5833ffd084bb4b6e2c02921e3326b",
            "placeholder": "​",
            "style": "IPY_MODEL_a25b5637f2fa46f696653dd4499116fb",
            "value": " 170499072/? [00:06&lt;00:00, 28486479.89it/s]"
          }
        },
        "2e39ad257bcc41bd8330c125f0116fd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a5f6cb5b63c41d49848c6106568d99b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38a45412449949b790408f332821c8a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "322226b73b3542f882889fa2d1b82731": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abd731f91d1c4566b3f144f91e04954c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ab5833ffd084bb4b6e2c02921e3326b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a25b5637f2fa46f696653dd4499116fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f242dd79c0b4f84ae8d8aefcbecd350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7eb971dc07f84f65b68e83a6be546652",
              "IPY_MODEL_7f9e90013c4a43ebac3f2174c74beb86",
              "IPY_MODEL_eb6dc01a7fca4244832f5f7acdc2de04"
            ],
            "layout": "IPY_MODEL_f09c4bc4ece240dc92beeb65e7f094a0"
          }
        },
        "7eb971dc07f84f65b68e83a6be546652": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b519db963044a30bfd458549b10694f",
            "placeholder": "​",
            "style": "IPY_MODEL_7dc1bce0837c46e09f5db94ba4b1857c",
            "value": "100%"
          }
        },
        "7f9e90013c4a43ebac3f2174c74beb86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64f6aadf8edd418db534c3b5e99b159c",
            "max": 46830571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0fcff79e9e5949829b9e323ec613740e",
            "value": 46830571
          }
        },
        "eb6dc01a7fca4244832f5f7acdc2de04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7df0cd17f7145a08f94013396e37ba6",
            "placeholder": "​",
            "style": "IPY_MODEL_256ba0602e3741de81d691d2cd6bd20d",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 138MB/s]"
          }
        },
        "f09c4bc4ece240dc92beeb65e7f094a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b519db963044a30bfd458549b10694f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dc1bce0837c46e09f5db94ba4b1857c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64f6aadf8edd418db534c3b5e99b159c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fcff79e9e5949829b9e323ec613740e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7df0cd17f7145a08f94013396e37ba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "256ba0602e3741de81d691d2cd6bd20d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install backpack-for-pytorch==1.3.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neBll2dM_17M",
        "outputId": "7cbb0b91-b5ad-4b81-d6cf-194022567bfd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting backpack-for-pytorch==1.3.0\n",
            "  Downloading backpack_for_pytorch-1.3.0-py3-none-any.whl (119 kB)\n",
            "\u001b[K     |████████████████████████████████| 119 kB 12.6 MB/s \n",
            "\u001b[?25hCollecting einops<1.0.0,>=0.3.0\n",
            "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: torchvision<1.0.0,>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from backpack-for-pytorch==1.3.0) (0.11.1+cu111)\n",
            "Requirement already satisfied: torch<2.0.0,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from backpack-for-pytorch==1.3.0) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0.0,>=1.6.0->backpack-for-pytorch==1.3.0) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision<1.0.0,>=0.7.0->backpack-for-pytorch==1.3.0) (1.21.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision<1.0.0,>=0.7.0->backpack-for-pytorch==1.3.0) (7.1.2)\n",
            "Installing collected packages: einops, backpack-for-pytorch\n",
            "Successfully installed backpack-for-pytorch-1.3.0 einops-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper"
      ],
      "metadata": {
        "id": "UqqeZ0rx94Qv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "\n",
        "class FedLogger:\n",
        "\n",
        "    __instance = None\n",
        "    __restart = None\n",
        "\n",
        "    \"\"\"\n",
        "    Initialize\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def getLogger(restart, filename):\n",
        "        \"\"\" Static access method. \"\"\"\n",
        "        if FedLogger.__instance is None:\n",
        "            FedLogger(filename)\n",
        "        else:\n",
        "            # Update logger\n",
        "            FedLogger.__update_logger(filename)\n",
        "\n",
        "        FedLogger.__restart = restart\n",
        "        return FedLogger.__instance\n",
        "\n",
        "    def __init__(self, filename):\n",
        "        \"\"\" Virtually private constructor. \"\"\"\n",
        "        if FedLogger.__instance != None:\n",
        "            raise Exception(\"Logger is a singleton!\")\n",
        "        else:\n",
        "            FedLogger.__instance = self\n",
        "            FedLogger.__update_logger(filename)\n",
        "\n",
        "    \"\"\"\n",
        "    Private method\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def __update_logger(filename):\n",
        "\n",
        "        if FedLogger.__instance is None:\n",
        "            raise Exception(\"Please init logger first!\")\n",
        "\n",
        "        logger = logging.getLogger()\n",
        "\n",
        "        for handler in logger.handlers[:]:\n",
        "            logger.removeHandler(handler)\n",
        "\n",
        "        logger.setLevel(logging.INFO)\n",
        "\n",
        "        formatter = logging.Formatter(\n",
        "            \"%(asctime)s [%(levelname)s] %(message)s\")\n",
        "\n",
        "        file_handler = logging.FileHandler(filename)\n",
        "        file_handler.setFormatter(formatter)\n",
        "        logger.addHandler(file_handler)\n",
        "\n",
        "        stream_handler = logging.StreamHandler()\n",
        "        stream_handler.setFormatter(formatter)\n",
        "        logger.addHandler(stream_handler)\n",
        "\n",
        "    \"\"\"\n",
        "    Public method\n",
        "    \"\"\"\n",
        "\n",
        "    def log(self, msg):\n",
        "        logger = logging.getLogger()\n",
        "        logger.info(\"Restart - {}, {}\".format(FedLogger.__restart, msg))"
      ],
      "metadata": {
        "id": "7-KgOJL395mZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import torch\n",
        "from torch import nn, autograd\n",
        "\n",
        "from backpack import backpack, extend\n",
        "from backpack.extensions import SumGradSquared, Variance\n",
        "\n",
        "\"\"\"\n",
        "Fishr\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def compute_irm_penalty(logits, y, loss_fn):\n",
        "    scale = torch.tensor(1.).requires_grad_()\n",
        "    if torch.cuda.is_available():\n",
        "        scale = torch.tensor(1.).cuda().requires_grad_()\n",
        "    loss = loss_fn(logits * scale, y)\n",
        "    grad = autograd.grad(loss, [scale], create_graph=True)[0]\n",
        "    return torch.sum(grad**2)\n",
        "\n",
        "\n",
        "def compute_grad_variance(input, labels, network, algorithm):\n",
        "    \"\"\"\n",
        "    Main Fishr method that computes the gradient variances using the BackPACK package.\n",
        "    \"\"\"\n",
        "    logits = network(input)\n",
        "    # bce_extended = extend(nn.BCEWithLogitsLoss(reduction='sum'))\n",
        "    bce_extended = extend(nn.CrossEntropyLoss(reduction='sum'))\n",
        "    loss = bce_extended(logits, labels)\n",
        "\n",
        "    # print('Prediction: {}'.format(logits))\n",
        "    # print('Real: {}'.format(labels))\n",
        "    # calling first-order derivatives in the network while maintaining the per-sample gradients\n",
        "\n",
        "    with backpack(Variance(), SumGradSquared()):\n",
        "        loss.backward(\n",
        "            inputs=list(network.parameters()), retain_graph=True, create_graph=True\n",
        "        )\n",
        "\n",
        "    dict_grads_variance = {\n",
        "        name: (\n",
        "            weights.variance.clone().view(-1)\n",
        "            if \"notcentered\" not in algorithm.split(\"_\") else\n",
        "            weights.sum_grad_squared.clone().view(-1)/input.size(0)\n",
        "        ) for name, weights in network.named_parameters() if (\n",
        "            \"onlyextractor\" not in algorithm.split(\"_\") or\n",
        "            name not in [\"4.weight\", \"4.bias\"]\n",
        "        )\n",
        "    }\n",
        "\n",
        "    return dict_grads_variance\n",
        "\n",
        "\n",
        "def l2_between_dicts(dict_1, dict_2):\n",
        "    assert len(dict_1) == len(dict_2)\n",
        "    dict_1_values = [dict_1[key] for key in sorted(dict_1.keys())]\n",
        "    dict_2_values = [dict_2[key] for key in sorted(dict_1.keys())]\n",
        "    return (\n",
        "        torch.cat(tuple([t.view(-1) for t in dict_1_values])) -\n",
        "        torch.cat(tuple([t.view(-1) for t in dict_2_values]))\n",
        "    ).pow(2).sum()\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "ILC\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def get_model_grads(input, labels, network, loss_fn):\n",
        "\n",
        "    _, logits = network(input)\n",
        "\n",
        "    loss = loss_fn(logits, labels)\n",
        "    loss.backward()\n",
        "\n",
        "    model_params = list(network.parameters())\n",
        "    param_gradients = []\n",
        "    for model_param in model_params:\n",
        "        # Get gradients\n",
        "        # Note: The gradient of the loss each parameter p is stored in p.grad after the backward\n",
        "        # See: https://discuss.pytorch.org/t/how-to-get-gradient-of-loss/16955\n",
        "        grad = model_param.grad\n",
        "        grad_copy = copy.deepcopy(grad)\n",
        "        param_gradients.append(grad_copy)\n",
        "\n",
        "    return param_gradients\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Arithmetic mean\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def compute_arith_mean(model_params, total_param_gradients):\n",
        "\n",
        "    param_gradients = [[] for _ in model_params]\n",
        "\n",
        "    # Loop for each environment\n",
        "    for env_param_gradients in total_param_gradients:\n",
        "        for idx, grads in enumerate(param_gradients):\n",
        "            env_grad = env_param_gradients[idx]\n",
        "            grads.append(env_grad)\n",
        "\n",
        "    assert len(param_gradients) == len(model_params)\n",
        "\n",
        "    for param, grads in zip(model_params, param_gradients):\n",
        "\n",
        "        # Calculate sign matrix\n",
        "        grads = torch.stack(grads, dim=0)\n",
        "        avg_grad = torch.mean(grads, dim=0)\n",
        "        param.grad = avg_grad\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Geometric mean\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def compute_geo_mean(model_params, total_param_gradients, algorithm, substitute):\n",
        "\n",
        "    if \"geo_substitute\" == algorithm:\n",
        "        compute_substitute_geo_mean(\n",
        "            model_params, total_param_gradients, substitute)\n",
        "    elif \"geo_weighted\" == algorithm:\n",
        "        compute_weighted_geo_mean(model_params, total_param_gradients)\n",
        "\n",
        "\n",
        "def compute_substitute_geo_mean(model_params, total_param_gradients, substitute):\n",
        "\n",
        "    param_gradients = [[] for _ in model_params]\n",
        "\n",
        "    # Loop for each environment\n",
        "    for env_param_gradients in total_param_gradients:\n",
        "        for idx, grads in enumerate(param_gradients):\n",
        "            env_grad = env_param_gradients[idx]\n",
        "            grads.append(env_grad)\n",
        "\n",
        "    assert len(param_gradients) == len(model_params)\n",
        "\n",
        "    for param, grads in zip(model_params, param_gradients):\n",
        "\n",
        "        # Calculate sign matrix\n",
        "        grads = torch.stack(grads, dim=0)\n",
        "        sign_matrix = torch.sign(grads)\n",
        "\n",
        "        avg_sign_matrix = torch.mean(sign_matrix, dim=0)\n",
        "\n",
        "        # If torch.sign(avg_sign_matrix) == 0, then has equal number of positive and negative numbers\n",
        "        # Regard the positive numbers are majority signs\n",
        "        avg_sign = torch.sign(avg_sign_matrix) + (avg_sign_matrix == 0)\n",
        "\n",
        "        majority_sign_matrix = sign_matrix == avg_sign\n",
        "        minority_sign_matrix = ~majority_sign_matrix\n",
        "\n",
        "        grads = majority_sign_matrix * grads + minority_sign_matrix * substitute\n",
        "\n",
        "        n_agreement_envs = len(grads)\n",
        "        avg_grad = torch.mean(grads, dim=0)\n",
        "        substitute_prod_grad = torch.sign(avg_grad) * torch.exp(\n",
        "            torch.sum(torch.log(torch.abs(grads) + 1e-10), dim=0) / n_agreement_envs)\n",
        "\n",
        "        param.grad = substitute_prod_grad\n",
        "\n",
        "\n",
        "def compute_weighted_geo_mean(model_params, total_param_gradients):\n",
        "\n",
        "    param_gradients = [[] for _ in model_params]\n",
        "\n",
        "    # Loop for each environment\n",
        "    for env_param_gradients in total_param_gradients:\n",
        "        for idx, grads in enumerate(param_gradients):\n",
        "            env_grad = env_param_gradients[idx]\n",
        "            grads.append(env_grad)\n",
        "\n",
        "    assert len(param_gradients) == len(model_params)\n",
        "\n",
        "    for param, grads in zip(model_params, param_gradients):\n",
        "\n",
        "        # Calculate sign matrix\n",
        "        grads = torch.stack(grads, dim=0)\n",
        "        sign_matrix = torch.sign(grads)\n",
        "\n",
        "        # Positive & Negative gradients\n",
        "        positive_sign_matrix = sign_matrix > 0\n",
        "        negative_sign_matrix = ~positive_sign_matrix\n",
        "\n",
        "        # Temporarily replace 0 with 1 to calculate geometric mean\n",
        "        positive_gradients = positive_sign_matrix * grads + negative_sign_matrix\n",
        "        negative_gradients = negative_sign_matrix * grads + positive_sign_matrix\n",
        "\n",
        "        # Temporarily replace 0 with 1 to prevent demoninator to be 0\n",
        "        n_agreement_envs = len(grads)\n",
        "        n_positive_envs = torch.sum(positive_sign_matrix, dim=0)\n",
        "        n_negative_envs = torch.sum(negative_sign_matrix, dim=0)\n",
        "\n",
        "        n_positive_envs_denominator = n_positive_envs + (n_positive_envs == 0)\n",
        "        n_negative_envs_denominator = n_negative_envs + (n_negative_envs == 0)\n",
        "\n",
        "        # Weighted geometric mean\n",
        "        positive_prod_gradients = (n_positive_envs / n_agreement_envs) * torch.exp(torch.sum(\n",
        "            torch.log(torch.abs(positive_gradients) + 1e-10), dim=0) / n_positive_envs_denominator)\n",
        "        negative_prod_gradients = (n_negative_envs / n_agreement_envs) * torch.exp(torch.sum(\n",
        "            torch.log(torch.abs(negative_gradients) + 1e-10), dim=0) / n_negative_envs_denominator)\n",
        "\n",
        "        weighted_prod_grad = positive_prod_gradients - negative_prod_gradients\n",
        "        param.grad = weighted_prod_grad"
      ],
      "metadata": {
        "id": "1fHCZ_e-975j"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loader"
      ],
      "metadata": {
        "id": "1P_EJGgy9gxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC, abstractmethod\n",
        "from enum import Enum\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Data Loader Type\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class DataLoaderType(Enum):\n",
        "    COLOR_MNIST = 0\n",
        "    ROTATE_CIFAR = 1\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Abstract Data Loader\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class AbstractDataLoader(ABC):\n",
        "\n",
        "    @abstractmethod\n",
        "    def combine_envs(self, envs):\n",
        "        raise Exception(\"Abstract method should be implemented\")\n",
        "\n",
        "    @abstractmethod\n",
        "    def make_environment(self, images, labels, **kwargs):\n",
        "        raise Exception(\"Abstract method should be implemented\")\n",
        "\n",
        "    def create_data_loader(self, x, y, batch_size):\n",
        "\n",
        "        data_set = self.__convert_to_tensor(x, y)\n",
        "        data_loader = DataLoader(data_set,\n",
        "                                 shuffle=True,\n",
        "                                 batch_size=batch_size)\n",
        "        return data_loader\n",
        "\n",
        "    def __convert_to_tensor(self, x, y):\n",
        "        assert x.shape[0] == y.shape[0]\n",
        "\n",
        "        tensor_list = []\n",
        "        for idx in range(x.shape[0]):\n",
        "            data_x, data_y = x[idx], y[idx]\n",
        "            tensor_list.append((data_x, data_y))\n",
        "\n",
        "        return tensor_list\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Color MNIST\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class ColorMNISTDataLoader(AbstractDataLoader):\n",
        "\n",
        "    def combine_envs(self, envs):\n",
        "        raise Exception(\"Method is not supported!\")\n",
        "\n",
        "    def make_environment(self, images, labels, **kwargs):\n",
        "\n",
        "        label_flipping_prob = kwargs.get(\"label_flipping_prob\")\n",
        "        if label_flipping_prob is None:\n",
        "            raise Exception(\"Need label flipping probability!\")\n",
        "\n",
        "        color_flipping_prob = kwargs.get(\"color_flipping_prob\")\n",
        "        if color_flipping_prob is None:\n",
        "            raise Exception(\"Need color flipping probability!\")\n",
        "\n",
        "        def torch_bernoulli(p, size):\n",
        "            return (torch.rand(size) < p).float()\n",
        "\n",
        "        def torch_xor(a, b):\n",
        "            return (a - b).abs()  # Assumes both inputs are either 0 or 1\n",
        "\n",
        "        # 2x subsample for computational convenience\n",
        "        images = images.reshape((-1, 28, 28))[:, ::2, ::2]\n",
        "        # Assign a binary label based on the digit; flip label with probability\n",
        "        labels = (labels < 5).float()\n",
        "        labels = torch_xor(labels, torch_bernoulli(\n",
        "            label_flipping_prob, len(labels)))\n",
        "        # Assign a color based on the label; flip the color with probability e\n",
        "        colors = torch_xor(labels, torch_bernoulli(\n",
        "            color_flipping_prob, len(labels)))\n",
        "        # Apply the color to the image by zeroing out the other color channel\n",
        "        images = torch.stack([images, images], dim=1)\n",
        "        images[torch.tensor(range(len(images))),\n",
        "               (1 - colors).long(), :, :] *= 0\n",
        "\n",
        "        images, labels = images.float() / 255., labels[:, None]\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            return {'images': images.cuda(), 'labels': labels.cuda()}\n",
        "\n",
        "        return {'images': images, 'labels': labels}\n",
        "\n",
        "    def create_data_loader(self, x, y, batch_size):\n",
        "        return super().create_data_loader(x, y, batch_size)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Rotated CIFAR-10\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class RotatedCifarDataLoader(AbstractDataLoader):\n",
        "\n",
        "    def combine_envs(self, envs):\n",
        "\n",
        "        images, labels = [], []\n",
        "        for env in envs:\n",
        "            image, label = env[\"images\"], env[\"labels\"]\n",
        "            images.append(image)\n",
        "            labels.append(label)\n",
        "\n",
        "        images = torch.cat(tuple(images))\n",
        "        labels = torch.cat(tuple(labels))\n",
        "\n",
        "        return {'images': images, 'labels': labels}\n",
        "\n",
        "    def make_environment(self, images, labels, **kwargs):\n",
        "\n",
        "        from_angle = kwargs.get('from_angle')\n",
        "        to_angle = kwargs.get('to_angle')\n",
        "\n",
        "        if from_angle is None:\n",
        "            raise Exception(\"Need from angle!\")\n",
        "\n",
        "        if to_angle is None:\n",
        "            raise Exception(\"Need to angle!\")\n",
        "\n",
        "        rotation = transforms.Compose([transforms.ToPILImage(),\n",
        "                                       transforms.RandomRotation(\n",
        "                                           degrees=(from_angle, to_angle)),\n",
        "                                       transforms.ToTensor()])\n",
        "\n",
        "        # images = images[:, ::2, ::2, :]\n",
        "        x = torch.zeros(len(images), 3, 32, 32)\n",
        "        for i in range(len(images)):\n",
        "            x[i] = rotation(images[i])\n",
        "\n",
        "        images = x\n",
        "\n",
        "        images, labels = torch.Tensor(images), torch.Tensor(labels)\n",
        "        labels = labels.type(torch.int64)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            return {'images': images.cuda(), 'labels': labels.cuda()}\n",
        "\n",
        "        return {'images': images, 'labels': labels}\n",
        "\n",
        "    def create_data_loader(self, x, y, batch_size):\n",
        "        return super().create_data_loader(x, y, batch_size)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Data Loader Factory\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class DataLoaderFactory:\n",
        "\n",
        "    __color_mnist = None\n",
        "    __rotate_cifar = None\n",
        "\n",
        "    @staticmethod\n",
        "    def get_data_loader(type):\n",
        "\n",
        "        if type == DataLoaderType.COLOR_MNIST:\n",
        "            if DataLoaderFactory.__color_mnist is None:\n",
        "                DataLoaderFactory.__color_mnist = ColorMNISTDataLoader()\n",
        "            return DataLoaderFactory.__color_mnist\n",
        "\n",
        "        elif type == DataLoaderType.ROTATE_CIFAR:\n",
        "            if DataLoaderFactory.__rotate_cifar is None:\n",
        "                DataLoaderFactory.__rotate_cifar = RotatedCifarDataLoader()\n",
        "            return DataLoaderFactory.__rotate_cifar\n",
        "\n",
        "        else:\n",
        "            raise Exception(\"Unsupported data loader type: {}\".format(type))\n"
      ],
      "metadata": {
        "id": "BnlYtjVs9ifh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "yKY1i3QM-BD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import torchvision\n",
        "from backpack import extend\n",
        "\n",
        "\"\"\"CIFAR ResNet\"\"\"\n",
        "\n",
        "\n",
        "class CifarResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, in_features, out_features):\n",
        "\n",
        "        super(CifarResNet, self).__init__()\n",
        "        self.network = torchvision.models.resnet18(pretrained=True)\n",
        "        self.classifier = extend(nn.Linear(in_features=in_features,\n",
        "                                    out_features=out_features))\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        features = self.network(input)\n",
        "        logits = self.classifier(features)\n",
        "        return features, logits\n",
        "\n",
        "\n",
        "\"\"\"MNIST MLP\"\"\"\n",
        "\n",
        "\n",
        "class MnistMLP(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(MnistMLP, self).__init__()\n",
        "\n",
        "        lin1 = nn.Linear(2 * 14 * 14, hidden_dim)\n",
        "        lin2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "        self.classifier = (nn.Linear(hidden_dim, 1))\n",
        "        for lin in [lin1, lin2, self.classifier]:\n",
        "            nn.init.xavier_uniform_(lin.weight)\n",
        "            nn.init.zeros_(lin.bias)\n",
        "\n",
        "        self._main = nn.Sequential(\n",
        "            lin1, nn.ReLU(True), lin2, nn.ReLU(True))\n",
        "        self.alllayers = extend(\n",
        "            nn.Sequential(lin1, nn.ReLU(True), lin2,\n",
        "                          nn.ReLU(True), self.classifier)\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def prepare_input(input):\n",
        "        return input.view(input.shape[0], 2 * 14 * 14)\n",
        "\n",
        "    def forward(self, input):\n",
        "        out = self.prepare_input(input)\n",
        "        features = self._main(out)\n",
        "        logits = self.classifier(features)\n",
        "        return features, torch.sigmoid(logits)\n"
      ],
      "metadata": {
        "id": "IKaJeFLB-CC7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainer"
      ],
      "metadata": {
        "id": "8eJsHMGZ9nLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from helper import *\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "\n",
        "    def __init__(self, evaluator_helper):\n",
        "        self.__evaluator_helper = evaluator_helper\n",
        "\n",
        "    def set_logger(self, logger):\n",
        "        self.__logger = logger\n",
        "\n",
        "    def train_model(self, model, optimizer, local_model, local_optimizer, train_loader, train_images, train_labels, round_idx, flags):\n",
        "\n",
        "        # t = torch.cuda.get_device_properties(0).total_memory\n",
        "        # a = torch.cuda.memory_allocated(0)\n",
        "\n",
        "        # logger.info(\"Memory before calculating gradients:\")\n",
        "        # logger.info(convert_size(t))\n",
        "        # logger.info(convert_size(a))\n",
        "\n",
        "        algorithm = flags.algorithm\n",
        "\n",
        "        if \"fishr\" in algorithm.split(\"_\") and (\"geo\" in algorithm.split(\"_\") or \"arith\" in algorithm.split(\"_\")):\n",
        "\n",
        "            \"\"\" Fishr + Geo Mean \"\"\"\n",
        "            final_loss = 0\n",
        "            final_acc = 0\n",
        "\n",
        "            total_param_gradients = []\n",
        "\n",
        "            # Set mode to train model\n",
        "            model.train()\n",
        "\n",
        "            # Start training\n",
        "            for (images, labels) in train_loader:\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                param_gradients = get_model_grads(\n",
        "                    images, labels, model, self.__evaluator_helper.mean_nll)\n",
        "\n",
        "                _, logits = model(images)\n",
        "                loss = self.__evaluator_helper.mean_nll(logits, labels)\n",
        "                acc = self.__evaluator_helper.mean_accuracy(logits, labels)\n",
        "\n",
        "                final_loss += loss\n",
        "                final_acc += acc\n",
        "\n",
        "                total_param_gradients.append(param_gradients)\n",
        "\n",
        "            # self.__logger.log(len(total_param_gradients))\n",
        "\n",
        "            # ILC\n",
        "            local_model_params = model.state_dict()\n",
        "            local_model_params = copy.deepcopy(local_model_params)\n",
        "            local_model.load_state_dict(local_model_params)\n",
        "\n",
        "            # TODO\n",
        "            local_model.train()\n",
        "            local_optimizer.zero_grad()\n",
        "            if \"geo\" in algorithm.split(\"_\"):\n",
        "                compute_geo_mean(list(local_model.parameters()),\n",
        "                                 total_param_gradients, \"geo_weighted\", 0.001)\n",
        "            elif \"arith\" in algorithm.split(\"_\"):\n",
        "                compute_arith_mean(\n",
        "                    list(local_model.parameters()), total_param_gradients)\n",
        "            local_optimizer.step()\n",
        "\n",
        "            # Fishr\n",
        "            features, _ = local_model(train_images)\n",
        "            grad_statistics = compute_grad_variance(\n",
        "                features, train_labels, local_model.classifier, algorithm)\n",
        "\n",
        "            # Calculate loss and accuracy\n",
        "            train_loss = final_loss / len(train_loader)\n",
        "            train_acc = final_acc / len(train_loader)\n",
        "\n",
        "        else:\n",
        "\n",
        "            # Set mode to train model\n",
        "            model.train()\n",
        "\n",
        "            # Start training\n",
        "            features, logits = model(train_images)\n",
        "\n",
        "            self.__logger.log(logits.shape)\n",
        "            self.__logger.log(train_labels.shape)\n",
        "\n",
        "            train_loss = self.__evaluator_helper.mean_nll(logits, train_labels)\n",
        "            train_acc = self.__evaluator_helper.mean_accuracy(\n",
        "                logits, train_labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if \"arith\" in algorithm.split(\"_\") or \"geo\" in algorithm.split(\"_\") or \"hybrid\" in algorithm.split(\"_\"):\n",
        "                model_grads = get_model_grads(\n",
        "                    train_images, train_labels, model, self.__evaluator_helper.mean_nll)\n",
        "\n",
        "            if \"fishr\" in algorithm.split(\"_\"):\n",
        "                grad_variance = compute_grad_variance(\n",
        "                    features, train_labels, model.classifier, algorithm)\n",
        "\n",
        "            if \"hybrid\" in algorithm.split(\"_\"):\n",
        "                grad_statistics = (grad_variance, model_grads)\n",
        "            elif \"fishr\" in algorithm.split(\"_\"):\n",
        "                grad_statistics = grad_variance\n",
        "            else:\n",
        "                # Arithmetic or geometric mean\n",
        "                grad_statistics = model_grads\n",
        "\n",
        "        # t = torch.cuda.get_device_properties(0).total_memory\n",
        "        # a = torch.cuda.memory_allocated(0)\n",
        "\n",
        "        # logger.info(\"Memory after calculating gradients:\")\n",
        "        # logger.info(convert_size(t))\n",
        "        # logger.info(convert_size(a))\n",
        "\n",
        "        return train_loss, train_acc, grad_statistics\n"
      ],
      "metadata": {
        "id": "tAAEKOHh9q2d"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluator"
      ],
      "metadata": {
        "id": "0hYebRz79xSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC, abstractmethod\n",
        "from enum import Enum\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import auc\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\"\"\"\n",
        "Evaluator Helper Type\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class EvaluatorHelperType(Enum):\n",
        "    BINARY = 0\n",
        "    MULTIPLE = 1\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Abstract Evaluator Helper\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class AbstractEvaluatorHelper(ABC):\n",
        "\n",
        "    @abstractmethod\n",
        "    def mean_nll(self, logits, y):\n",
        "        raise Exception(\"Abstract method should be implemented\")\n",
        "\n",
        "    @abstractmethod\n",
        "    def mean_accuracy(self, logits, y):\n",
        "        raise Exception(\"Abstract method should be implemented\")\n",
        "\n",
        "    @abstractmethod\n",
        "    def mean_roc_auc(self, logits, y):\n",
        "        raise Exception()\n",
        "\n",
        "    @abstractmethod\n",
        "    def mean_pr_auc(self, logits, y):\n",
        "        raise Exception()\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Binary Classification\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class BinaryClassificationEvaluatorHelper(AbstractEvaluatorHelper):\n",
        "\n",
        "    def mean_nll(self, logits, y):\n",
        "        critetion = nn.BCELoss()\n",
        "        return critetion(logits, y)\n",
        "\n",
        "    def mean_accuracy(self, logits, y):\n",
        "        preds = (logits > 0.5).float()\n",
        "        return ((preds - y).abs() < 1e-2).float().mean()\n",
        "\n",
        "    def mean_roc_auc(self, logits, y):\n",
        "        preds = (logits > 0.5).float()\n",
        "        y = y.detach().cpu().numpy()\n",
        "        preds = preds.detach().cpu().numpy()\n",
        "        return roc_auc_score(y, preds)\n",
        "\n",
        "    def mean_pr_auc(self, logits, y):\n",
        "        preds = (logits > 0.5).float()\n",
        "        y = y.detach().cpu().numpy()\n",
        "        preds = preds.detach().cpu().numpy()\n",
        "        precision, recall, _ = precision_recall_curve(y, preds)\n",
        "        return auc(recall, precision)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Multi Classification\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class MultiClassificationEvaluatorHelper(AbstractEvaluatorHelper):\n",
        "\n",
        "    def mean_nll(self, logits, y):\n",
        "        critetion = nn.CrossEntropyLoss()\n",
        "        return critetion(logits, y)\n",
        "\n",
        "    def mean_accuracy(self, logits, y):\n",
        "        _, preds = torch.max(logits, 1)\n",
        "        correct = (preds == y).sum().item()\n",
        "        total = y.size(0)\n",
        "        return correct / total\n",
        "\n",
        "    def mean_roc_auc(self, logits, y):\n",
        "        return None\n",
        "\n",
        "    def mean_pr_auc(self, logits, y):\n",
        "        return None\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Evaluator Helper Factory\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class EvaluatorHelperFactory:\n",
        "\n",
        "    __binary = None\n",
        "    __multi = None\n",
        "\n",
        "    @staticmethod\n",
        "    def get_evaluator(type):\n",
        "\n",
        "        if type == EvaluatorHelperType.BINARY:\n",
        "            if EvaluatorHelperFactory.__binary is None:\n",
        "                EvaluatorHelperFactory.__binary = BinaryClassificationEvaluatorHelper()\n",
        "            return EvaluatorHelperFactory.__binary\n",
        "\n",
        "        elif type == EvaluatorHelperType.MULTIPLE:\n",
        "            if EvaluatorHelperFactory.__multi is None:\n",
        "                EvaluatorHelperFactory.__multi = MultiClassificationEvaluatorHelper()\n",
        "            return EvaluatorHelperFactory.__multi\n",
        "\n",
        "        else:\n",
        "            raise Exception(\n",
        "                \"Unsupported evaluator helper type: {}\".format(type))"
      ],
      "metadata": {
        "id": "0Ys3Xhk_9yeM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "class Evaluator:\n",
        "\n",
        "    def __init__(self, helper):\n",
        "        self.__helper = helper\n",
        "\n",
        "    def evaluate_model(self, model, test_loader, test_batch_size):\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Set mode to evaluate model\n",
        "            model.eval()\n",
        "\n",
        "            # Start evaluating model\n",
        "            final_loss = 0\n",
        "            final_acc = 0\n",
        "            final_roc = []\n",
        "            final_pr = []\n",
        "\n",
        "            for (images, labels) in test_loader:\n",
        "\n",
        "                _, logits = model(images)\n",
        "\n",
        "                loss = self.__helper.mean_nll(logits, labels)\n",
        "                acc = self.__helper.mean_accuracy(logits, labels)\n",
        "\n",
        "                final_loss += loss\n",
        "                final_acc += acc\n",
        "\n",
        "                if len(labels) == test_batch_size:\n",
        "                    roc = self.__helper.mean_roc_auc(logits, labels)\n",
        "                    pr = self.__helper.mean_pr_auc(logits, labels)\n",
        "                    if roc is not None:\n",
        "                        final_roc.append(roc)\n",
        "                    if pr is not None:\n",
        "                        final_pr.append(pr)\n",
        "\n",
        "            test_loss = final_loss / len(test_loader)\n",
        "            test_acc = final_acc / len(test_loader)\n",
        "\n",
        "            test_roc = None\n",
        "            if len(final_roc) > 0:\n",
        "                test_roc = sum(final_roc) / len(final_roc)\n",
        "\n",
        "            test_pr = None\n",
        "            if len(final_pr) > 0:\n",
        "                test_pr = sum(final_pr) / len(final_pr)\n",
        "\n",
        "            return test_loss, test_acc, test_roc, test_pr"
      ],
      "metadata": {
        "id": "cSYSlaJH9zJ-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Client"
      ],
      "metadata": {
        "id": "LaeF-Z0K9lq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "class FederatedClient:\n",
        "\n",
        "    # Init client\n",
        "    def __init__(self, trainer, evaluator,  client_id, local_model,\n",
        "                 train_loader, train_images, train_labels,\n",
        "                 test_loader, learning_rate, logger):\n",
        "\n",
        "        self.trainer = trainer\n",
        "        self.evaluator = evaluator\n",
        "\n",
        "        self.client_id = client_id\n",
        "\n",
        "        self.train_loader = train_loader\n",
        "        self.test_loader = test_loader\n",
        "\n",
        "        self.train_images = train_images\n",
        "        self.train_labels = train_labels\n",
        "\n",
        "        self.local_model = local_model\n",
        "        self.logger = logger\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            self.local_model = self.local_model.to('cuda')\n",
        "\n",
        "        self.local_optimizer = torch.optim.Adam(self.local_model.parameters(),\n",
        "                                                lr=learning_rate)\n",
        "\n",
        "    # Train model\n",
        "\n",
        "    def train(self, global_model, global_optimizer, round_idx, flags):\n",
        "\n",
        "        # Start training\n",
        "        dict_grad_statistics = None\n",
        "        train_loss, train_acc, dict_grad_statistics = self.trainer.train_model(global_model,\n",
        "                                                                               global_optimizer,\n",
        "                                                                               self.local_model,\n",
        "                                                                               self.local_optimizer,\n",
        "                                                                               self.train_loader,\n",
        "                                                                               self.train_images,\n",
        "                                                                               self.train_labels,\n",
        "                                                                               round_idx,\n",
        "                                                                               flags)\n",
        "        train_history = (train_loss, train_acc)\n",
        "        self.logger.log('Client[{}], Round [{}], Loss: [{}], Accuracy: [{}]'.format(\n",
        "            self.client_id, round_idx + 1, train_loss, train_acc))\n",
        "\n",
        "        # Evaluation\n",
        "        test_batch_size = flags.test_batch_size\n",
        "        test_history = self.evaluator.evaluate_model(global_model,\n",
        "                                                     self.test_loader,\n",
        "                                                     test_batch_size)\n",
        "\n",
        "        return train_history, test_history, dict_grad_statistics\n"
      ],
      "metadata": {
        "id": "6b7iHx0I9JOT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Executor"
      ],
      "metadata": {
        "id": "fRKJcsxl-E7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC, abstractmethod\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Executor Interface\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class AbstractExecutor(ABC):\n",
        "\n",
        "    @abstractmethod\n",
        "    def __init__(self):\n",
        "        raise Exception(\"Abstract method should be implemented\")\n",
        "\n",
        "    @abstractmethod\n",
        "    def is_eligible_executor(self, dataset):\n",
        "        raise Exception(\"Abstract method should be implemented\")\n",
        "\n",
        "    @abstractmethod\n",
        "    def run(self, restart, flags):\n",
        "        raise Exception(\"Abstract method should be implemented\")"
      ],
      "metadata": {
        "id": "-We4r7O0-GD1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from abstract_executor import AbstractExecutor\n",
        "\n",
        "\n",
        "class ColorMNISTExecutor(AbstractExecutor):\n",
        "\n",
        "    COLOR_MNIST_DATASET = \"color_mnist\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def is_eligible_executor(self, dataset):\n",
        "        return dataset == self.COLOR_MNIST_DATASET\n",
        "\n",
        "    def run(self, restart, flags):\n",
        "\n",
        "        algorithm = flags.algorithm\n",
        "\n",
        "        total_feature = flags.total_feature\n",
        "        learning_rate = flags.learning_rate\n",
        "        weight_decay = flags.weight_decay\n",
        "\n",
        "        # learning_rate_decay_step_size = 100\n",
        "        # learning_rate_decay = 0.98\n",
        "\n",
        "        train_batch_size = flags.train_batch_size\n",
        "        test_batch_size = flags.test_batch_size\n",
        "\n",
        "        num_steps = flags.num_steps\n",
        "        num_rounds = flags.num_rounds\n",
        "        num_epochs = flags.num_epochs\n",
        "\n",
        "        hidden_dim = flags.hidden_dim\n",
        "\n",
        "        penalty_anneal_iters = flags.penalty_anneal_iters\n",
        "        penalty_weight_factor = flags.penalty_weight_factor\n",
        "        penalty_weight = flags.penalty_weight\n",
        "\n",
        "        return super().run(flags)"
      ],
      "metadata": {
        "id": "MXcOL9dJABww"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from abstract_executor import AbstractExecutor\n",
        "# from client import FederatedClient\n",
        "# from fed_logger import FedLogger\n",
        "# from trainer import Trainer\n",
        "# from evaluator import Evaluator\n",
        "# from evaluator_helper import *\n",
        "# from data_loader import *\n",
        "# from model import *\n",
        "# from helper import *\n",
        "\n",
        "from torchvision import datasets\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class RotateCifarExecutor(AbstractExecutor):\n",
        "\n",
        "    ROTATE_CIFAR_DATASET = \"rotate_cifar\"\n",
        "\n",
        "    \"\"\"Initialize\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.data_loader = DataLoaderFactory.get_data_loader(\n",
        "            DataLoaderType.ROTATE_CIFAR)\n",
        "        self.evaluator_helper = EvaluatorHelperFactory.get_evaluator(\n",
        "            EvaluatorHelperType.MULTIPLE)\n",
        "        self.trainer = Trainer(self.evaluator_helper)\n",
        "        self.evaluator = Evaluator(self.evaluator_helper)\n",
        "\n",
        "    \"\"\"Public Methods\"\"\"\n",
        "\n",
        "    def is_eligible_executor(self, dataset):\n",
        "        return dataset == self.ROTATE_CIFAR_DATASET\n",
        "\n",
        "    def run(self, restart, flags):\n",
        "\n",
        "        algorithm = flags.algorithm\n",
        "\n",
        "        self.logger = FedLogger.getLogger(restart + 1,\n",
        "                                          \"cifar-{}-restart {}\".format(algorithm, restart + 1))\n",
        "        self.trainer.set_logger(self.logger)\n",
        "\n",
        "        learning_rate = flags.learning_rate\n",
        "        weight_decay = flags.weight_decay\n",
        "\n",
        "        # learning_rate_decay_step_size = 100\n",
        "        # learning_rate_decay = 0.98\n",
        "\n",
        "        train_batch_size = flags.train_batch_size\n",
        "        test_batch_size = flags.test_batch_size\n",
        "\n",
        "        num_rounds = flags.num_rounds\n",
        "\n",
        "        penalty_anneal_iters = flags.penalty_anneal_iters\n",
        "        penalty_weight_factor = flags.penalty_weight_factor\n",
        "        penalty_weight = flags.penalty_weight\n",
        "\n",
        "        train_envs, test_envs, ood_validation = self.__load_dataset()\n",
        "        clients = self.__create_clients(\n",
        "            train_envs, test_envs, train_batch_size, test_batch_size, learning_rate)\n",
        "\n",
        "        global_model = CifarResNet(1000, 10)\n",
        "        if torch.cuda.is_available():\n",
        "            global_model = global_model.to('cuda')\n",
        "\n",
        "        global_optimizer = torch.optim.Adam(global_model.parameters(),\n",
        "                                            lr=learning_rate,\n",
        "                                            weight_decay=weight_decay)\n",
        "        final_train_loss_history = []\n",
        "        final_train_acc_history = []\n",
        "        final_test_loss_history = []\n",
        "        final_test_acc_history = []\n",
        "        final_ood_loss_history = []\n",
        "        final_ood_acc_history = []\n",
        "        # final_ood_pr_history = []\n",
        "        # final_ood_roc_history = []\n",
        "\n",
        "        best_model = None\n",
        "        best_round = 0\n",
        "        best_loss = float(\"inf\")\n",
        "        best_acc = 0\n",
        "        # best_pr_auc = 0\n",
        "        # best_roc_auc = 0\n",
        "\n",
        "        for round_idx in range(num_rounds):\n",
        "\n",
        "            self.logger.log('\\n')\n",
        "            self.logger.log('########################################')\n",
        "            self.logger.log('Start training round: {}'.format(round_idx + 1))\n",
        "            self.logger.log('########################################')\n",
        "            self.logger.log('\\n')\n",
        "\n",
        "            # 1. Load global params\n",
        "            global_params = global_model.state_dict()\n",
        "\n",
        "            # 2. Federated training\n",
        "            train_loss_history, train_acc_history = [], []\n",
        "            test_loss_history, test_acc_history = [], []\n",
        "            model_grads_history, grads_variance_history = [], []\n",
        "\n",
        "            for client in clients:\n",
        "\n",
        "                train_history, test_history, dict_grad_statistics = client.train(\n",
        "                    global_model, global_optimizer, round_idx, flags)\n",
        "\n",
        "                train_loss, train_acc = train_history\n",
        "                test_loss, test_acc, _, _ = test_history\n",
        "\n",
        "                train_loss_history.append(train_loss)\n",
        "                train_acc_history.append(train_acc)\n",
        "\n",
        "                test_loss_history.append(test_loss)\n",
        "                test_acc_history.append(test_acc)\n",
        "\n",
        "                if \"hybrid\" in algorithm.split(\"_\"):\n",
        "                    grad_variance, model_grads = dict_grad_statistics\n",
        "                    grads_variance_history.append(grad_variance)\n",
        "                    model_grads_history.append(model_grads)\n",
        "                elif \"fishr\" in algorithm.split(\"_\"):\n",
        "                    grads_variance_history.append(dict_grad_statistics)\n",
        "                else:\n",
        "                    model_grads_history.append(dict_grad_statistics)\n",
        "\n",
        "            final_train_loss = torch.stack(train_loss_history).mean()\n",
        "            final_train_acc = sum(train_acc_history) / len(train_acc_history)\n",
        "\n",
        "            final_test_loss = torch.stack(test_loss_history).mean()\n",
        "            final_test_acc = sum(test_acc_history) / len(test_acc_history)\n",
        "\n",
        "            final_train_loss_np = final_train_loss.detach().cpu().numpy().copy()\n",
        "            final_train_acc_np = final_train_acc\n",
        "            final_test_loss_np = final_test_loss.detach().cpu().numpy().copy()\n",
        "            final_test_acc_np = final_test_acc\n",
        "\n",
        "            final_train_loss_history.append(final_train_loss_np)\n",
        "            final_train_acc_history.append(final_train_acc_np)\n",
        "            final_test_loss_history.append(final_test_loss_np)\n",
        "            final_test_acc_history.append(final_test_acc_np)\n",
        "\n",
        "            # 3. Arithmetic mean / geometric mean\n",
        "            if \"arith\" in algorithm.split(\"_\") and \"fishr\" not in algorithm.split(\"_\"):\n",
        "                global_optimizer.zero_grad()\n",
        "                compute_arith_mean(\n",
        "                    list(global_model.parameters()), model_grads_history)\n",
        "                global_optimizer.step()\n",
        "\n",
        "                self.logger.log(\">>>>>>>>> Arith mean learning rate:\")\n",
        "                for param_group in global_optimizer.param_groups:\n",
        "                    self.logger.log(param_group['lr'])\n",
        "\n",
        "                # global_scheduler.step()\n",
        "\n",
        "            if \"geo\" in algorithm.split(\"_\") and \"fishr\" not in algorithm.split(\"_\"):\n",
        "                global_optimizer.zero_grad()\n",
        "                compute_geo_mean(list(global_model.parameters()),\n",
        "                                 model_grads_history, algorithm, 0.001)\n",
        "                global_optimizer.step()\n",
        "\n",
        "            # 4. Update global parameter based on gradients\n",
        "            if \"fishr\" in algorithm.split(\"_\"):\n",
        "\n",
        "                dict_grad_statistics_averaged = {}\n",
        "\n",
        "                first_dict_grad_statistics = grads_variance_history[0]\n",
        "                for name in first_dict_grad_statistics:\n",
        "\n",
        "                    grads_list = []\n",
        "                    for dict_grad_statistics in grads_variance_history:\n",
        "                        grads = dict_grad_statistics[name]\n",
        "                        grads_list.append(grads)\n",
        "\n",
        "                    dict_grad_statistics_averaged[name] = torch.stack(\n",
        "                        grads_list, dim=0).mean(dim=0)\n",
        "\n",
        "                fishr_penalty = 0\n",
        "                for dict_grad_statistics in grads_variance_history:\n",
        "                    fishr_penalty += l2_between_dicts(\n",
        "                        dict_grad_statistics, dict_grad_statistics_averaged)\n",
        "\n",
        "                if \"hybrid\" in algorithm.split(\"_\"):\n",
        "\n",
        "                    # Hybrid fishr\n",
        "                    weight_norm = torch.tensor(0.)\n",
        "                    if torch.cuda.is_available():\n",
        "                        weight_norm = torch.tensor(0.).cuda()\n",
        "                    for w in global_model.parameters():\n",
        "                        grad = w.grad\n",
        "                        weight_norm += w.norm().pow(2)\n",
        "\n",
        "                    # if round_idx % 10 == 0 and round_idx != 0:\n",
        "                    #     penalty_weight *= 1.01\n",
        "                    # self.logger.log(\"***** Penalty weight: {}\".format(penalty_weight))\n",
        "                    # penalty_weight = (penalty_weight_factor if round_idx >= penalty_anneal_iters else 1.0)\n",
        "\n",
        "                    # loss = weight_decay * weight_norm + penalty_weight * fishr_penalty\n",
        "                    # loss = penalty_weight * fishr_penalty\n",
        "                    penalty_weight = (\n",
        "                        penalty_weight_factor if round_idx >= penalty_anneal_iters else penalty_weight)\n",
        "                    \n",
        "                    if penalty_weight > 1.0:\n",
        "                        model_grads_history = model_grads_history / penalty_weight\n",
        "                    else:\n",
        "                        loss = penalty_weight * fishr_penalty\n",
        "\n",
        "                    # Gradients computed by fishr loss\n",
        "                    global_optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "\n",
        "                    model_params = list(global_model.parameters())\n",
        "                    fishr_gradients = []\n",
        "                    for model_param in model_params:\n",
        "                        grad = model_param.grad\n",
        "                        grad_copy = copy.deepcopy(grad.detach())\n",
        "                        fishr_gradients.append(grad_copy)\n",
        "\n",
        "                    # First, update model using geometric mean\n",
        "                    global_optimizer.zero_grad()\n",
        "                    compute_geo_mean(list(global_model.parameters()),\n",
        "                                     model_grads_history, 'geo_weighted', 0.001)\n",
        "                    global_optimizer.step()\n",
        "\n",
        "                    self.logger.log(\">>>>>>>>> Geo mean learning rate:\")\n",
        "                    for param_group in global_optimizer.param_groups:\n",
        "                        self.logger.log(param_group['lr'])\n",
        "\n",
        "                    # Then, update model using fishr loss\n",
        "                    global_optimizer.zero_grad()\n",
        "                    updated_model_params = list(global_model.parameters())\n",
        "\n",
        "                    for param, grads in zip(updated_model_params, fishr_gradients):\n",
        "                        param.grad = grads\n",
        "\n",
        "                    global_optimizer.step()\n",
        "\n",
        "                    self.logger.log(\">>>>>>>>> Fishr learning rate:\")\n",
        "                    for param_group in global_optimizer.param_groups:\n",
        "                        self.logger.log(param_group['lr'])\n",
        "\n",
        "                    # global_scheduler.step()\n",
        "\n",
        "                else:\n",
        "\n",
        "                    loss = final_train_loss.clone()\n",
        "\n",
        "                    weight_norm = torch.tensor(0.)\n",
        "                    if torch.cuda.is_available():\n",
        "                        weight_norm = torch.tensor(0.).cuda()\n",
        "                    for w in global_model.parameters():\n",
        "                        grad = w.grad\n",
        "                        weight_norm += w.norm().pow(2)\n",
        "\n",
        "                    # loss += weight_decay * weight_norm\n",
        "\n",
        "                    self.logger.log('Before Loss: {}'.format(loss))\n",
        "                    penalty_weight = (\n",
        "                        penalty_weight_factor if round_idx >= penalty_anneal_iters else penalty_weight)\n",
        "\n",
        "                    loss += penalty_weight * fishr_penalty\n",
        "                    if penalty_weight > 1.0:\n",
        "                        # Rescale the entire loss to keep backpropagated gradients in a reasonable range\n",
        "                        loss /= penalty_weight\n",
        "                    self.logger.log('Fishr Loss: {}'.format(fishr_penalty))\n",
        "                    self.logger.log('After Loss: {}'.format(loss))\n",
        "\n",
        "                    # Vanilla fishr\n",
        "                    global_optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    global_optimizer.step()\n",
        "\n",
        "                    self.logger.log(\">>>>>>>>> Fishr learning rate:\")\n",
        "                    for param_group in global_optimizer.param_groups:\n",
        "                        self.logger.log(param_group['lr'])\n",
        "\n",
        "                    # global_scheduler.step()\n",
        "\n",
        "            # 5. Evaluation\n",
        "            ood_test_images, ood_test_labels = ood_validation[\"images\"], ood_validation[\"labels\"]\n",
        "            ood_test_loader = self.data_loader.create_data_loader(\n",
        "                ood_test_images, ood_test_labels, test_batch_size)\n",
        "            ood_test_history = self.evaluator.evaluate_model(global_model,\n",
        "                                                             ood_test_loader,\n",
        "                                                             test_batch_size)\n",
        "            ood_test_loss, ood_test_acc, _, _ = ood_test_history\n",
        "\n",
        "            ood_test_loss_np = ood_test_loss.detach().cpu().numpy().copy()\n",
        "            ood_test_acc_np = ood_test_acc\n",
        "\n",
        "            final_ood_loss_history.append(ood_test_loss_np)\n",
        "            final_ood_acc_history.append(ood_test_acc_np)\n",
        "            # final_ood_roc_history.append(ood_test_roc)\n",
        "\n",
        "            if ood_test_loss < best_loss and round_idx > 5:\n",
        "                best_loss = ood_test_loss\n",
        "                best_acc = ood_test_acc\n",
        "                # best_roc_auc = ood_test_roc\n",
        "                # best_pr_auc = odd_test_pr\n",
        "                best_model = global_model\n",
        "                best_round = round_idx\n",
        "\n",
        "            self.logger.log('\\n')\n",
        "            self.logger.log('########################################')\n",
        "            self.logger.log('End training round: {}'.format(round_idx + 1))\n",
        "            self.logger.log('[Train] Loss: {}, Accuracy: {}'.format(\n",
        "                final_train_loss, final_train_acc))\n",
        "            self.logger.log('[Test] Loss: {}, Accuracy: {}'.format(\n",
        "                final_test_loss, final_test_acc))\n",
        "            self.logger.log('[OOD Test] Loss: {}, Accuracy: {}'.format(\n",
        "                ood_test_loss, ood_test_acc))\n",
        "            self.logger.log('########################################')\n",
        "            self.logger.log('\\n')\n",
        "\n",
        "            if round_idx % 10 == 0 and round_idx > 5:\n",
        "                self.logger.log(learning_rate)\n",
        "                path = 'cifar-{}-restart-{}-output_checkpoint{}'.format(\n",
        "                    algorithm, restart, str(round_idx))\n",
        "                self.logger.log(global_model.state_dict())\n",
        "                torch.save({'global_model': global_model.state_dict(),\n",
        "                            'best_model': best_model.state_dict(),\n",
        "                            'best_round': best_round,\n",
        "                            'best_loss': best_loss,\n",
        "                            # 'best_roc_auc': best_roc_auc,\n",
        "                            # 'best_pr_auc': best_pr_auc,\n",
        "                            'best_acc': best_acc,\n",
        "                            'global_optimizer': global_optimizer.state_dict(),\n",
        "                            'final_train_loss_history': final_train_loss_history,\n",
        "                            'final_train_acc_history': final_train_acc_history,\n",
        "                            'final_test_loss_history': final_test_loss_history,\n",
        "                            'final_test_acc_history': final_test_acc_history,\n",
        "                            'final_ood_loss_history': final_ood_loss_history,\n",
        "                            'final_ood_acc_history': final_ood_acc_history}, path)\n",
        "\n",
        "        best_loss = best_loss.cpu().numpy().copy()\n",
        "\n",
        "        plt.title('Train & Test Loss')\n",
        "        plt.plot(final_train_loss_history, label='train_loss')\n",
        "        plt.plot(final_test_loss_history, label='test_loss')\n",
        "        plt.plot(final_ood_loss_history, label='ood_test_loss')\n",
        "        plt.ylim(0, 5)\n",
        "        plt.hlines(best_loss, 0, best_round, linestyles='dashed')\n",
        "        plt.xlabel('Round')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend(['Train Loss', 'Test Loss', 'OOD Test Loss'])\n",
        "        plt.savefig('loss-{}-restart {}.png'.format(algorithm, restart + 1))\n",
        "        plt.close()\n",
        "\n",
        "        plt.title('Train & Test Accuracy')\n",
        "        plt.plot(final_train_acc_history, label='train_acc')\n",
        "        plt.plot(final_test_acc_history, label='test_acc')\n",
        "        plt.plot(final_ood_acc_history, label='ood_test_acc')\n",
        "        plt.ylim(0, 1)\n",
        "        plt.hlines(best_acc, 0, best_round, linestyles='dashed')\n",
        "        plt.xlabel('Round')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend(['Train Accuracy', 'Test Accuracy', 'OOD Test Accuracy'])\n",
        "        plt.savefig('acc-{}-restart {}.png'.format(algorithm, restart + 1))\n",
        "        plt.close()\n",
        "\n",
        "        self.logger.log(\"Best Loss: {}\".format(best_loss))\n",
        "        self.logger.log(\"Best Accuracy: {}\".format(best_acc))\n",
        "        self.logger.log(\"Best Round: {}\".format(best_round))\n",
        "\n",
        "    \"\"\"\n",
        "    ### Load Dataset\n",
        "    \"\"\"\n",
        "\n",
        "    def __load_dataset(self):\n",
        "\n",
        "        cifar = datasets.CIFAR10('~/datasets/cifar', train=True, download=True)\n",
        "\n",
        "        cifar_train = (cifar.data[:40000], cifar.targets[:40000])\n",
        "        cifar_val = (cifar.data[40000:], cifar.targets[40000:])\n",
        "\n",
        "        rng_state = np.random.get_state()\n",
        "        np.random.shuffle(cifar_train[0])\n",
        "        np.random.set_state(rng_state)\n",
        "        np.random.shuffle(cifar_train[1])\n",
        "\n",
        "        self.logger.log((cifar_val[0]).shape)\n",
        "\n",
        "        train_client_1_env_1 = self.data_loader.make_environment(\n",
        "            cifar_train[0][:30000:6], cifar_train[1][:30000:6], from_angle=10, to_angle=10)\n",
        "        train_client_1_env_2 = self.data_loader.make_environment(\n",
        "            cifar_train[0][1:30001:6], cifar_train[1][1:30001:6], from_angle=25, to_angle=25)\n",
        "        train_client_1_env_3 = self.data_loader.make_environment(\n",
        "            cifar_train[0][2:30002:6], cifar_train[1][2:30002:6], from_angle=40, to_angle=40)\n",
        "\n",
        "        train_client_2_env_1 = self.data_loader.make_environment(\n",
        "            cifar_train[0][3:30003:6], cifar_train[1][3:30003:6], from_angle=60, to_angle=60)\n",
        "        train_client_2_env_2 = self.data_loader.make_environment(\n",
        "            cifar_train[0][4:30004:6], cifar_train[1][4:30004:6], from_angle=75, to_angle=75)\n",
        "        train_client_2_env_3 = self.data_loader.make_environment(\n",
        "            cifar_train[0][5:30005:6], cifar_train[1][5:30005:6], from_angle=90, to_angle=90)\n",
        "\n",
        "        train_envs = [\n",
        "            # Client 1 Train\n",
        "            self.data_loader.combine_envs([train_client_1_env_1,\n",
        "                                           train_client_1_env_2, train_client_1_env_3]),\n",
        "            # Client 2 Train\n",
        "            self.data_loader.combine_envs([train_client_2_env_1,\n",
        "                                           train_client_2_env_2, train_client_2_env_3])\n",
        "        ]\n",
        "\n",
        "        test_client_1_env_1 = self.data_loader.make_environment(\n",
        "            cifar_train[0][30000::6], cifar_train[1][30000::6], from_angle=10, to_angle=10)\n",
        "        test_client_1_env_2 = self.data_loader.make_environment(\n",
        "            cifar_train[0][30001::6], cifar_train[1][30001::6], from_angle=25, to_angle=25)\n",
        "        test_client_1_env_3 = self.data_loader.make_environment(\n",
        "            cifar_train[0][30002::6], cifar_train[1][30002::6], from_angle=40, to_angle=40)\n",
        "\n",
        "        test_client_2_env_1 = self.data_loader.make_environment(\n",
        "            cifar_train[0][30003::6], cifar_train[1][30003::6], from_angle=60, to_angle=60)\n",
        "        test_client_2_env_2 = self.data_loader.make_environment(\n",
        "            cifar_train[0][30004::6], cifar_train[1][30004::6], from_angle=75, to_angle=75)\n",
        "        test_client_2_env_3 = self.data_loader.make_environment(\n",
        "            cifar_train[0][30005::6], cifar_train[1][30005::6], from_angle=90, to_angle=90)\n",
        "\n",
        "        test_envs = [\n",
        "            # Client 1 Validation\n",
        "            self.data_loader.combine_envs([test_client_1_env_1, test_client_1_env_2,\n",
        "                                           test_client_1_env_3]),\n",
        "            # Client 2 Validation\n",
        "            self.data_loader.combine_envs([test_client_2_env_1,\n",
        "                                           test_client_2_env_2, test_client_2_env_3])\n",
        "        ]\n",
        "\n",
        "        ood_validation = self.data_loader.make_environment(\n",
        "            cifar_val[0], cifar_val[1], from_angle=-90, to_angle=90)\n",
        "\n",
        "        return train_envs, test_envs, ood_validation\n",
        "\n",
        "    \"\"\"\n",
        "    ### Create federated clients\n",
        "    \"\"\"\n",
        "\n",
        "    def __create_clients(self, train_envs, test_envs, train_batch_size, test_batch_size, learning_rate):\n",
        "\n",
        "        # Create federated clients\n",
        "        clients = []\n",
        "\n",
        "        for client_id, (train_env, test_env) in enumerate(zip(train_envs, test_envs)):\n",
        "\n",
        "            train_images, train_labels = train_env[\"images\"], train_env[\"labels\"]\n",
        "            test_images, test_labels = test_env[\"images\"], test_env[\"labels\"]\n",
        "\n",
        "            train_loader = self.data_loader.create_data_loader(\n",
        "                train_images, train_labels, train_batch_size)\n",
        "            test_loader = self.data_loader.create_data_loader(\n",
        "                test_images, test_labels, test_batch_size)\n",
        "\n",
        "            # Each client has one local model\n",
        "            local_model = CifarResNet(1000, 10)\n",
        "            client = FederatedClient(self.trainer, self.evaluator, client_id, local_model,\n",
        "                                     train_loader, train_images, train_labels,\n",
        "                                     test_loader, learning_rate, self.logger)\n",
        "            clients.append(client)\n",
        "\n",
        "        return clients\n"
      ],
      "metadata": {
        "id": "lJGazWVu-JAR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "GXX6UROB-Oup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from executor_color_mnist import ColorMNISTExecutor\n",
        "# from executor_rotate_cifar import RotateCifarExecutor\n",
        "\n",
        "import argparse\n",
        "import torch\n",
        "\n",
        "# if not torch.cuda.is_available():\n",
        "#     raise Exception(\"Please use CUDA environment!\")\n",
        "\n",
        "# parser = argparse.ArgumentParser()\n",
        "\n",
        "# \"\"\" Select dataset \"\"\"\n",
        "# parser.add_argument(\n",
        "#     '--dataset',\n",
        "#     type=str,\n",
        "#     default=\"color_mnist\",\n",
        "#     choices=[\n",
        "#         'color_mnist',\n",
        "#         'rotate_cifar',\n",
        "#         'e_icu'\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "# \"\"\" Select algorithm \"\"\"\n",
        "# parser.add_argument(\n",
        "#     '--algorithm',\n",
        "#     type=str,\n",
        "#     default=\"fishr\",\n",
        "#     choices=[\n",
        "#         'arith',  # Arithmetic mean\n",
        "#         'geo_weighted',  # Geometric mean (weighted)\n",
        "#         'geo_substitute',  # Geometric mean (substituted)\n",
        "#         'fishr',  # Fishr\n",
        "#         'fishr_geo'  # Inter-silo fishr + intra-silo geometric mean\n",
        "#         'fishr_hybrid',  # Inter-silo fishr + inter-silo geometric mean\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "# parser.add_argument('--total_feature', type=int, default=2 * 14 * 14)\n",
        "\n",
        "# parser.add_argument('--learning_rate', type=float, default=0.0001)\n",
        "# parser.add_argument('--weight_decay', type=float, default=0.001)\n",
        "\n",
        "# parser.add_argument('--train_batch_size', type=int, default=32)\n",
        "# parser.add_argument('--test_batch_size', type=int, default=32)\n",
        "\n",
        "# parser.add_argument('--hidden_dim', type=int, default=390)\n",
        "\n",
        "# \"\"\" Federated Learning \"\"\"\n",
        "# parser.add_argument('--num_restarts', type=int, default=5)  # Total experiments\n",
        "# parser.add_argument('--num_rounds', type=int, default=501)  # Federated rounds\n",
        "# # Epochs per federated round\n",
        "# parser.add_argument('--num_epochs', type=int, default=1)\n",
        "\n",
        "# \"\"\" Fishr \"\"\"\n",
        "# parser.add_argument('--penalty_anneal_iters', type=int, default=0)\n",
        "# parser.add_argument('--penalty_weight_factor', type=float, default=1.0)\n",
        "# parser.add_argument('--penalty_weight', type=float, default=1.0)\n",
        "\n",
        "\n",
        "# flags = parser.parse_args()\n",
        "\n",
        "class Flags:\n",
        "    dataset = \"rotate_cifar\"\n",
        "    algorithm = \"fishr\"\n",
        "    total_feature = 2 * 14 * 14\n",
        "    learning_rate = 0.0003\n",
        "    weight_decay = 0.001\n",
        "    train_batch_size = 32\n",
        "    test_batch_size = 32\n",
        "    hidden_dim = 390\n",
        "    num_restarts = 1\n",
        "    num_rounds = 101\n",
        "    num_epochs = 1\n",
        "    penalty_anneal_iters = 50\n",
        "    penalty_weight_factor = 1.0\n",
        "    penalty_weight = 0.5\n",
        "\n",
        "flags = Flags()\n",
        "\n",
        "# for k, v in sorted(vars(flags).items()):\n",
        "#     print(\"\\t{}: {}\".format(k, v))\n",
        "\n",
        "dataset = flags.dataset\n",
        "\n",
        "# Find eligible executor based on dataset\n",
        "eligible_executor = None\n",
        "executors = [ColorMNISTExecutor(), RotateCifarExecutor()]\n",
        "\n",
        "for executor in executors:\n",
        "    if executor.is_eligible_executor(dataset):\n",
        "        eligible_executor = executor\n",
        "        break\n",
        "\n",
        "if eligible_executor is None:\n",
        "    raise Exception(\n",
        "        \"Unable to find eligible executor for dataset: {}\".format(dataset))\n",
        "\n",
        "# Execute training\n",
        "num_restarts = flags.num_restarts\n",
        "\n",
        "for restart in range(num_restarts):\n",
        "    print(\"Restart: {}\".format(restart))\n",
        "    eligible_executor.run(restart, flags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830,
          "referenced_widgets": [
            "92a96954d814418289a94f212fa9df68",
            "23768ce6627747668eee1d9fe5036790",
            "c63b25e173bc45ba97cf8c750b76ab19",
            "918aa19f47fa4620859ec03c7bc4be76",
            "2e39ad257bcc41bd8330c125f0116fd3",
            "6a5f6cb5b63c41d49848c6106568d99b",
            "38a45412449949b790408f332821c8a2",
            "322226b73b3542f882889fa2d1b82731",
            "abd731f91d1c4566b3f144f91e04954c",
            "6ab5833ffd084bb4b6e2c02921e3326b",
            "a25b5637f2fa46f696653dd4499116fb",
            "9f242dd79c0b4f84ae8d8aefcbecd350",
            "7eb971dc07f84f65b68e83a6be546652",
            "7f9e90013c4a43ebac3f2174c74beb86",
            "eb6dc01a7fca4244832f5f7acdc2de04",
            "f09c4bc4ece240dc92beeb65e7f094a0",
            "9b519db963044a30bfd458549b10694f",
            "7dc1bce0837c46e09f5db94ba4b1857c",
            "64f6aadf8edd418db534c3b5e99b159c",
            "0fcff79e9e5949829b9e323ec613740e",
            "b7df0cd17f7145a08f94013396e37ba6",
            "256ba0602e3741de81d691d2cd6bd20d"
          ]
        },
        "id": "YdPM3aX3-N6n",
        "outputId": "e6146234-46f0-4cc1-9305-a36cc65a8b14"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restart: 0\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/datasets/cifar/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92a96954d814418289a94f212fa9df68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/datasets/cifar/cifar-10-python.tar.gz to /root/datasets/cifar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-04-10 10:16:04,699 [INFO] Restart - 1, (10000, 32, 32, 3)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f242dd79c0b4f84ae8d8aefcbecd350"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-04-10 10:16:33,961 [INFO] Restart - 1, \n",
            "\n",
            "2022-04-10 10:16:33,964 [INFO] Restart - 1, ########################################\n",
            "2022-04-10 10:16:33,969 [INFO] Restart - 1, Start training round: 1\n",
            "2022-04-10 10:16:33,972 [INFO] Restart - 1, ########################################\n",
            "2022-04-10 10:16:33,974 [INFO] Restart - 1, \n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "2022-04-10 10:16:35,561 [INFO] Restart - 1, torch.Size([15000, 10])\n",
            "2022-04-10 10:16:35,562 [INFO] Restart - 1, torch.Size([15000])\n",
            "/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py:156: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at  ../torch/csrc/autograd/engine.cpp:976.)\n",
            "  allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "2022-04-10 10:16:35,628 [INFO] Restart - 1, Client[0], Round [1], Loss: [3.2789552211761475], Accuracy: [0.1008]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-4451e3b72d6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrestart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_restarts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Restart: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0meligible_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-831ebd8a5fed>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, restart, flags)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 train_history, test_history, dict_grad_statistics = client.train(\n\u001b[0;32m--> 106\u001b[0;31m                     global_model, global_optimizer, round_idx, flags)\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-fe1f9ecff42e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, global_model, global_optimizer, round_idx, flags)\u001b[0m\n\u001b[1;32m     43\u001b[0m                                                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                                                                                \u001b[0mround_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                                                                                flags)\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mtrain_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         self.logger.log('Client[{}], Round [{}], Loss: [{}], Accuracy: [{}]'.format(\n",
            "\u001b[0;32m<ipython-input-6-995b056a7e62>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, model, optimizer, local_model, local_optimizer, train_loader, train_images, train_labels, round_idx, flags)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-27d77d4b361c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2282\u001b[0m     return torch.batch_norm(\n\u001b[0;32m-> 2283\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2284\u001b[0m     )\n\u001b[1;32m   2285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 236.00 MiB (GPU 0; 11.17 GiB total capacity; 10.27 GiB already allocated; 88.81 MiB free; 10.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    }
  ]
}